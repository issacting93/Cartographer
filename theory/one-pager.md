# Interactional Cartography: Research Journey One-Pager

## Question 1: Do Human-AI Roles Even Exist?

**Answer: Yes, through social projection—but not like human roles**

- Roles exist because we unconsciously treat computers as social actors (CASA paradigm, Reeves & Nass 1996)
- **NOT** because AI is sentient or has autonomous agency
- Roles are **performative achievements** constructed through interaction
- Key concept: **Bounded personhood**—AI participates in role dynamics without possessing genuine authority or agency

## Question 2: Can We Classify Human-AI Roles?

**Answer: Yes, but classification reveals fundamental asymmetries**

### Approach: Social Role Theory (Parsons, Bales, Eagly)

| Theory | Core Contribution |
|--------|------------------|
| **Parsons (1951)** | Instrumental vs. Expressive distinction—social action serves task goals OR relationship maintenance |
| **Bales (1950s)** | Empirically validated role differentiation in groups—task specialists vs. social-emotional specialists emerge naturally |
| **Eagly (1987)** | Roles are socially learned and projected onto interaction partners through observation and enforcement |

### The 12-Role Taxonomy (Reduced Taxonomy v1.0)

| Dimension | Authority | Human Role | AI Role |
|-----------|-----------|------------|---------|
| **Instrumental** | High | Director | Expert-System, Advisor |
| **Instrumental** | Low | Information-Seeker, Provider | Learning-Facilitator, Task-Executor |
| **Instrumental** | Equal | Collaborator | Co-Constructor |
| **Expressive** | High | — | — |
| **Expressive** | Low | Social-Expressor | Social-Facilitator |
| **Expressive** | Equal | Relational-Peer, Explorer | Relational-Peer |

**Key distinction:** Learning-Facilitator (instrumental scaffolding) vs. Social-Facilitator (expressive rapport)

### What Classification Revealed

- **Instrumental collapse:** 98.8% human roles are task-oriented, only 1.2% expressive
- **AI similar:** 94.3% instrumental vs. 5.7% expressive
- **Authority-agency paradox:** AI positioned with high authority (Expert-System: 64.8%) but lacks genuine autonomy
- **Same roles, different experiences:** Identical role pairs show 41-82× variance in affective trajectories

**Problem:** Role labels describe **destinations** (where conversations end up) but miss **journeys** (how they get there)

## Question 3: Can We Better Visualize This?

**Answer: Yes—Conversational Cartography as spatial encoding**

### The 3D Spatial Framework

**X-Axis: Functional ↔ Social Orientation**
- 0.0 (Functional): Task completion, efficiency, information retrieval
- 1.0 (Social): Relationship building, play, self-expression
- From: Parsons' Instrumental/Expressive distinction

**Y-Axis: Aligned ↔ Divergent Structure**
- 0.0 (Divergent): Misalignment, contestation, repair sequences
- 1.0 (Aligned): Linguistic harmony, turn-taking symmetry, cooperation
- From: Linguistic Alignment Theory (Pickering & Garrod) + authority dynamics

**Z-Axis: Emotional Intensity**
- 0.0 (Valley): Calm, neutral, affiliated stability
- 1.0 (Peak): High arousal, frustration, intense engagement
- From: PAD Model (Pleasure-Arousal-Dominance)

### What We Learned (671 conversations, 3 datasets)

**Finding 1: Narrow Functional Corridors**
- 84.4% of conversations cluster in Functional-Aligned quadrant
- 72% in just 3 archetypal patterns (all instrumental/structured)
- **Implication:** Current paradigms systematically reduce interaction to instrumental exchange

**Finding 2: Empty Relational Territories**
- Social-Emergent quadrant: <7% of conversations
- Information-Seeker → Facilitator: 0.1% (1 out of 671)
- Co-constructive AI positioning: 7%
- **Implication:** Entire relational modes are **foreclosed by design**

**Finding 3: Trajectory Matters More Than Labels**
- 82.7% of clustering variance from **how conversations move** through space
- Spatial trajectory features: 56.9% of discriminative power
- Same role pairs with 41-82× variance in emotional intensity
- **Implication:** The journey through relational space matters more than role classification

**Finding 4: The Authority-Agency Tension**
- AI positioned with high authority (Expert-System 64.8%)
- AI messages 3.3× longer than user messages (floor dominance)
- But AI lacks autonomous agency to establish mutual authority
- This creates **structural asymmetry** visible as spatial concentration

**Finding 5: The Curation Paradox**
- OASST (curated for diversity): 93.3% functional-aligned, lowest variance
- WildChat (natural usage): 76.7% functional-aligned, 3.4× higher variance
- **Implication:** Quality curation filters against divergent interactions—"alignment" reinforces instrumental dominance

## The Stakes: What's Foreclosed

**Missing relational modes:**
- Co-construction (AI as collaborative partner)
- Facilitation (AI as guide enabling exploration)
- Expressive engagement (relationship-building, play)
- Collaborative negotiation (task-related contestation)

**These absences aren't inevitable—they're political, ethical, and designed.**

## The Provocation

> What if we designed for what's missing?

The empty quadrants don't represent impossible relationships—they represent **roads not taken, possibilities not pursued, relational modes not designed for.**

Conversational Cartography makes this foreclosure visible, creating space to confront a choice: continue designing AI as instrumental tools, or create affordances for relational modes currently excluded.

---

**Project:** Cartographer  
**Visualization:** https://[deployment-url]